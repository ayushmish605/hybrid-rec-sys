{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "584df3a8",
   "metadata": {},
   "source": [
    "# Scraper Testing Notebook\n",
    "\n",
    "**Purpose**: Test ONLY the web scrapers - no sentiment analysis, minimal database\n",
    "\n",
    "## What We Test\n",
    "1. ‚úÖ Gemini AI Search Term Generator\n",
    "2. ‚úÖ IMDb Rating Scraper  \n",
    "3. ‚úÖ IMDb Review Scraper\n",
    "4. ‚ö†Ô∏è  Reddit Scraper (needs API keys)\n",
    "5. ‚ö†Ô∏è  Twitter Scraper (optional)\n",
    "\n",
    "## What We DON'T Test\n",
    "- ‚ùå Sentiment analysis (NLP team)\n",
    "- ‚ùå Review weighting (NLP team)\n",
    "- ‚ùå Complex SQL operations\n",
    "- ‚ùå Recommendation models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad97b3",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b43836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Add src to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(f\"üìÅ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c3d0d",
   "metadata": {},
   "source": [
    "## Step 2: Test Gemini AI Search Term Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a550ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapers.gemini_search import GeminiSearchTermGenerator\n",
    "\n",
    "# Check API key\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "if not gemini_api_key:\n",
    "    print(\"‚ùå GEMINI_API_KEY not found in .env\")\n",
    "else:\n",
    "    print(f\"‚úÖ Gemini API key loaded: {gemini_api_key[:20]}...\")\n",
    "\n",
    "# Initialize generator\n",
    "gemini = GeminiSearchTermGenerator()\n",
    "print(\"‚úÖ Gemini generator initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5665dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Generate search terms for \"Inception\"\n",
    "print(\"üé¨ Testing Gemini with 'Inception (2010)'...\\n\")\n",
    "\n",
    "search_terms = gemini.generate_search_terms(\n",
    "    title=\"Inception\",\n",
    "    year=2010,\n",
    "    genres=[\"Action\", \"Sci-Fi\", \"Thriller\"],\n",
    "    overview=\"A thief who steals corporate secrets through dream-sharing technology.\"\n",
    ")\n",
    "\n",
    "print(\"üìä Result type:\", type(search_terms))\n",
    "print(\"üìä Keys:\", list(search_terms.keys()) if search_terms else \"None\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "if search_terms:\n",
    "    for platform, terms in search_terms.items():\n",
    "        print(f\"\\n{platform.upper()}:\")\n",
    "        for term in terms[:3]:  # Show first 3 terms\n",
    "            print(f\"  ‚Ä¢ {term}\")\n",
    "        if len(terms) > 3:\n",
    "            print(f\"  ... and {len(terms)-3} more\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No search terms generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75cdea9",
   "metadata": {},
   "source": [
    "## Step 3: Test IMDb Rating Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ada235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapers.imdb_scraper import IMDbScraper\n",
    "\n",
    "# Initialize scraper\n",
    "imdb = IMDbScraper(rate_limit=2.0)\n",
    "print(\"‚úÖ IMDb scraper initialized!\")\n",
    "print(\"‚è±Ô∏è  Rate limit: 2 seconds between requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be74f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Scrape rating for \"Inception\"\n",
    "print(\"üé¨ Testing IMDb rating scraper with 'Inception (2010)'...\\n\")\n",
    "\n",
    "rating_data = imdb.scrape_movie_rating(\n",
    "    title=\"Inception\",\n",
    "    year=2010\n",
    ")\n",
    "\n",
    "print(\"üìä Result type:\", type(rating_data))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "if rating_data:\n",
    "    print(\"\\n‚úÖ RATING DATA:\")\n",
    "    print(f\"  Rating: {rating_data.get('rating')}/10\")\n",
    "    print(f\"  Votes: {rating_data.get('vote_count'):,}\")\n",
    "    print(f\"  IMDb ID: {rating_data.get('imdb_id')}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No rating data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29001e7b",
   "metadata": {},
   "source": [
    "## Step 4: Test IMDb Review Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f176e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Scrape reviews for \"Zootopia\"\n",
    "print(\"üé¨ Testing IMDb review scraper with 'Zootopia (2016)'...\\n\")\n",
    "print(\"‚è±Ô∏è  This will take ~20 seconds (10 reviews with 2-second rate limit)\\n\")\n",
    "\n",
    "reviews = imdb.scrape_movie_reviews(\n",
    "    title=\"Zootopia\",\n",
    "    year=2016,\n",
    "    max_reviews=10\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"\\n‚úÖ Scraped {len(reviews)} reviews\\n\")\n",
    "\n",
    "if reviews:\n",
    "    print(\"üìä SAMPLE REVIEW (first one):\")\n",
    "    sample = reviews[0]\n",
    "    print(f\"\\n  Source: {sample.get('source')}\")\n",
    "    print(f\"  Rating: {sample.get('rating')}/10\")\n",
    "    print(f\"  Author: {sample.get('author')}\")\n",
    "    print(f\"  Helpful votes: {sample.get('helpful_count')}\")\n",
    "    print(f\"  Text preview: {sample.get('text', '')[:200]}...\")\n",
    "    print(f\"\\n  Full structure:\")\n",
    "    pprint({k: v for k, v in sample.items() if k != 'text'}, indent=4)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No reviews found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319317c7",
   "metadata": {},
   "source": [
    "## Step 5: Test Reddit Scraper (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Reddit API keys are available\n",
    "reddit_client_id = os.getenv('REDDIT_CLIENT_ID')\n",
    "reddit_client_secret = os.getenv('REDDIT_CLIENT_SECRET')\n",
    "\n",
    "if reddit_client_id and reddit_client_secret:\n",
    "    print(\"‚úÖ Reddit API keys found!\")\n",
    "    from scrapers.reddit_scraper import RedditScraper\n",
    "    \n",
    "    reddit = RedditScraper()\n",
    "    print(\"‚úÖ Reddit scraper initialized!\")\n",
    "    \n",
    "    # Test search\n",
    "    print(\"\\nüîç Searching Reddit for 'Inception movie discussion'...\\n\")\n",
    "    reddit_posts = reddit.search_posts(\n",
    "        search_terms=[\"Inception movie discussion\"],\n",
    "        max_results_per_term=5\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(reddit_posts)} Reddit posts\")\n",
    "    if reddit_posts:\n",
    "        print(\"\\nüìä SAMPLE POST:\")\n",
    "        sample = reddit_posts[0]\n",
    "        print(f\"  Subreddit: {sample.get('subreddit')}\")\n",
    "        print(f\"  Score: {sample.get('score')}\")\n",
    "        print(f\"  Text: {sample.get('text', '')[:200]}...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Reddit API keys not found in .env\")\n",
    "    print(\"   To test Reddit scraper, add:\")\n",
    "    print(\"   REDDIT_CLIENT_ID=your_id\")\n",
    "    print(\"   REDDIT_CLIENT_SECRET=your_secret\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad8dc7a",
   "metadata": {},
   "source": [
    "## Step 6: Test Twitter Scraper (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ö†Ô∏è  Twitter scraper uses snscrape (no API key needed)\")\n",
    "print(\"   However, Twitter/X has been restricting scraping recently.\")\n",
    "print(\"   Test at your own risk - may not work reliably.\\n\")\n",
    "\n",
    "# Uncomment to test:\n",
    "# from scrapers.twitter_scraper import TwitterScraper\n",
    "# twitter = TwitterScraper()\n",
    "# tweets = twitter.search_tweets(\n",
    "#     search_terms=[\"#Inception movie\"],\n",
    "#     max_tweets_per_term=5\n",
    "# )\n",
    "# print(f\"Found {len(tweets)} tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1464c",
   "metadata": {},
   "source": [
    "## Summary: Scraper Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1676d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SCRAPER TEST SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(\"‚úÖ Gemini AI: Generates search terms (dict with platform keys)\")\n",
    "print(\"‚úÖ IMDb Rating: Returns rating, vote count, IMDb ID\")\n",
    "print(\"‚úÖ IMDb Reviews: Returns list of review dictionaries\")\n",
    "print(\"‚ö†Ô∏è  Reddit: Needs API keys in .env\")\n",
    "print(\"‚ö†Ô∏è  Twitter: May not work due to platform restrictions\")\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(\"1. Scrapers are working independently ‚úÖ\")\n",
    "print(\"2. Data structures are correct ‚úÖ\")\n",
    "print(\"3. Ready to integrate with database\")\n",
    "print(\"4. NLP team can process scraped reviews\")\n",
    "print(\"5. Recommendation team can use rated movies\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
